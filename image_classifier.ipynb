{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Classifier Code\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(base_dir,labels):    \n",
    "    \"This function loads and preprocesses images.\"\n",
    "    print('Loading...')\n",
    "    \n",
    "    #directories for train and test images \n",
    "    test_dir = os.path.join(base_dir,'Test')\n",
    "    train_dir = os.path.join(base_dir,'Training')\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_valid = []\n",
    "    y_valid = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    no_of_classes = len(labels)\n",
    "    \n",
    "    for category in labels: \n",
    "        \n",
    "        #create paths for categories in labels \n",
    "        train_path = os.path.join(train_dir,category)  \n",
    "        test_path = os.path.join(test_dir,category)\n",
    "\n",
    "        #training images \n",
    "        for img in os.listdir(train_path):            \n",
    "            #cv2 images are BGR images, convert them to RGB images to be compatible with matplotlib.pyplot functions \n",
    "            img_array = cv2.cvtColor(cv2.imread(os.path.join(train_path,img)),cv2.COLOR_BGR2RGB)  # convert to array\n",
    "            \n",
    "            #fruits-360 images are 100x100 by default, so there is no need to change their sizes \n",
    "            #img_array = cv2.resize(img_array,(IMG_SIZE, IMG_SIZE)) \n",
    "            new_array = np.array(img_array)\n",
    "            x_train.append(new_array)\n",
    "            y_train.append(labels.index(category))\n",
    "        \n",
    "        #split test images into validation and test images by a ratio of 0.8\n",
    "        test_image_no = len(os.listdir(test_path))\n",
    "        split_no = int(test_image_no * 0.8)\n",
    "        \n",
    "        #validation images \n",
    "        for img in os.listdir(test_path)[:split_no]:\n",
    "            img_array = cv2.cvtColor(cv2.imread(os.path.join(test_path,img)),cv2.COLOR_BGR2RGB)  # convert to array\n",
    "            #img_array = cv2.resize(img_array,(IMG_SIZE, IMG_SIZE)) \n",
    "            new_array = np.array(img_array)\n",
    "            x_valid.append(new_array)\n",
    "            y_valid.append(labels.index(category))\n",
    "\n",
    "        #test images \n",
    "        for img in os.listdir(test_path)[split_no:]:\n",
    "            img_array = cv2.cvtColor(cv2.imread(os.path.join(test_path,img)),cv2.COLOR_BGR2RGB)  # convert to array\n",
    "            #img_array = cv2.resize(img_array,(IMG_SIZE, IMG_SIZE)) \n",
    "            new_array = np.array(img_array)\n",
    "            x_test.append(new_array)\n",
    "            y_test.append(labels.index(category))\n",
    "    \n",
    "    #prepare label vectors/target vectors\n",
    "    y_train = np_utils.to_categorical(y_train,no_of_classes)\n",
    "    y_test = np_utils.to_categorical(y_test,no_of_classes)\n",
    "    y_valid = np_utils.to_categorical(y_valid,no_of_classes)\n",
    "    \n",
    "    #convert list objects to numpy arrays \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    x_valid = np.array(x_valid)    \n",
    "    y_valid = np.array(y_valid)\n",
    "    \n",
    "    #re-scale so that all the pixel values lie within 0 to 1\n",
    "    x_train = x_train.astype('float32')/255\n",
    "    x_valid = x_valid.astype('float32')/255\n",
    "    x_test = x_test.astype('float32')/255\n",
    "\n",
    "    print('Done!')\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dir = '../input/fruits/fruits-360'\n",
    "labels = ['Apple Granny Smith', 'Apple Red 1', 'Avocado', 'Banana Lady Finger', 'Cocos', 'Corn', 'Eggplant', 'Mandarine', 'Pepper Green', 'Strawberry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fruits-360 images are 100x100\n",
    "IMG_SHAPE = 100\n",
    "\n",
    "NUM_CATEGORIES = len(labels)\n",
    "print('Fruit categories:', labels)\n",
    "print('Fruit category no:', NUM_CATEGORIES)\n",
    "          \n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test  = load_dataset(base_dir,labels)    \n",
    "print('Train image no:', x_train.shape[0])\n",
    "print('Validation image no:', x_valid.shape[0])\n",
    "print('Test image no:', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#let us see one of y_train's elements \n",
    "#only one element has value 1(corresponding to its label) and others are 0.\n",
    "print('y_train[0]:',y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#display sample images \n",
    "plt.imshow(x_train[0])\n",
    "plt.title('Train image')\n",
    "plt.savefig('sample_train_image.png')\n",
    "plt.show()\n",
    "index = np.argmax(y_train[0])\n",
    "print('Category:', labels[index])\n",
    "\n",
    "plt.imshow(x_valid[0])\n",
    "plt.title('Validation image')\n",
    "plt.savefig('sample_validation_image.png')\n",
    "plt.show()\n",
    "index = np.argmax(y_valid[0])\n",
    "print('Category:', labels[index])\n",
    "\n",
    "plt.imshow(x_test[0])\n",
    "plt.title('Test image')\n",
    "plt.savefig('sample_test_image.png')\n",
    "plt.show()\n",
    "index = np.argmax(y_test[0])\n",
    "print('Category:', labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model 1\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(IMG_SHAPE,IMG_SHAPE, 3)))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(NUM_CATEGORIES, activation='softmax'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Build model 2\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(16, (3,3), padding='same', activation='relu', input_shape=(IMG_SHAPE,IMG_SHAPE, 3)))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(NUM_CATEGORIES, activation='softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#Data augmentation on training set\n",
    "datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True,\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs1 = 10\n",
    "epochs2 = 5\n",
    "batch_size = 32 \n",
    "\n",
    "# fits the model on batches with real-time data augmentation\n",
    "history1 = model1.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train) / batch_size, epochs=epochs1, shuffle = True, \n",
    "                    validation_data=(x_valid, y_valid))\n",
    "                    \n",
    "history2 = model2.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train) / batch_size, epochs=epochs2, shuffle = True, \n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate and print test accuracy\n",
    "score1 = model1.evaluate(x_test, y_test, verbose=0)\n",
    "score2 = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\n', 'Test accuracy of model #1:', score1[1])\n",
    "print('\\n', 'Test accuracy of model #2:', score2[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_model_performance(history,epochs,model_name):\n",
    "    \n",
    "    \"This functions plots training and validation graphs\" \n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(1,epochs + 1)\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.savefig(model_name + \"_performance.png\")\n",
    "    plt.show()\n",
    "\n",
    "plot_model_performance(history1,epochs1,\"model_v1\")\n",
    "plot_model_performance(history2,epochs2,\"model_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#confusion matrix for test set\n",
    "y_pred2=model1.predict(x_test)\n",
    "y_pred_classes2=np.argmax(y_pred2,axis=1)\n",
    "y_true2=np.argmax(y_test,axis=1)\n",
    "\n",
    "#compute confusion matrix\n",
    "conf_mat2=tf.math.confusion_matrix(y_true2,y_pred_classes2)\n",
    "\n",
    "#plot the confusion matrix\n",
    "f,ax=plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat2,annot=True,fmt=\".0f\")\n",
    "ax.set_xticklabels(labels, rotation = 'vertical')\n",
    "ax.set_yticklabels(labels, rotation = 'horizontal')\n",
    "plt.savefig('model_v1_confusion_matrix.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for test set\n",
    "y_pred2=model2.predict(x_test)\n",
    "y_pred_classes2=np.argmax(y_pred2,axis=1)\n",
    "y_true2=np.argmax(y_test,axis=1)\n",
    "\n",
    "#compute confusion matrix\n",
    "conf_mat2=tf.math.confusion_matrix(y_true2,y_pred_classes2)\n",
    "\n",
    "#plot the confusion matrix\n",
    "f,ax=plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat2,annot=True,fmt=\".0f\")\n",
    "ax.set_xticklabels(labels, rotation = 'vertical')\n",
    "ax.set_yticklabels(labels, rotation = 'horizontal')\n",
    "plt.savefig('model_v2_confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_images(predictions, x_test, y_test, labels):\n",
    "        \n",
    "    # plot a random sample of test images, their predicted labels, and ground truth\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    \n",
    "    for i, index in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n",
    "        \n",
    "        ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(np.squeeze(x_test[index]))\n",
    "        pred_index = np.argmax(predictions[index])\n",
    "        true_index = np.argmax(y_test[index])\n",
    "        if pred_index == true_index:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        plt.xlabel(\"{} {:2.0f}%\".format(labels[pred_index],100*np.max(predictions[index]),labels[true_index]),color=color)\n",
    "   \n",
    "    plt.savefig(\"test_images.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "predictions = model2.predict(x_test)\n",
    "plot_test_images(predictions,x_test,y_test,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pip install h5py\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model1.to_json()\n",
    "with open(\"model_v1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model_json = model2.to_json()\n",
    "with open(\"model_v2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model1.save_weights(\"model_v1.h5\")\n",
    "model2.save_weights(\"model_v2.h5\")\n",
    "print(\"Saved models to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
